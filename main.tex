
\documentclass[12pt]{article}
\usepackage[margin=0.7in]{geometry}

\usepackage{amsmath}

\title{Evidence lower bounds with built-in baselines}
\author{Justin}
\date{\today}

\begin{document}
\maketitle

\section{Problem setup}
The goal is to maximize the log marginal likelihood,
\begin{equation}
\label{eqn:ml}
\log p(x) = \log \sum_z p(x,z),
\end{equation}
for a latent variable model.
The derivative of the above is 
\begin{equation}
\label{eqn:ml-grad}
\nabla \log \sum_z p(x,z)
= \frac{p(x,z)}{p(x)}\nabla \log p(x,z) = 
p(z\mid x)\nabla \log p(x,z),
\end{equation}
the expected gradient under the posterior.
When exact marginalization is intractable,
a common approach is to introduce a variational approximation to the posterior $q(z\mid x)$
and optimize the lower bound
\begin{equation}
\label{eqn:elbo}
\log p(x)
= \log \sum_z q(z\mid x) \frac{p(x,z)}{q(z\mid x)}
\ge \sum_z q(z\mid x) \log \frac{p(x,z)}{q(z\mid x)},
\end{equation}
which allows for tractable Monte Carlo approximation.
\footnote{
The gap between the two is given by $KL[q(z\mid x) || p(z \mid x)]$.
}

Empirically, we find directly optimizing this lower bound (\ref{eqn:elbo}) to be more difficult than
optimizing the marginal likelihood (\ref{eqn:ml}), often requiring a baseline:
\begin{equation}
\label{eqn:baseline}
\begin{aligned}
&\nabla_q \sum_z q(z\mid x) \log \frac{p(x,z)}{q(z\mid x)}\\
&= \nabla_q \sum_z q(z\mid x) \log p(x\mid z) - KL[q(z\mid x) || p(z)]\\
&= \nabla_q \sum_z q(z\mid x) (\log p(x\mid z) - B) - KL[q(z\mid x) || p(z)],
\end{aligned}
\end{equation}
where the baseline $B$ is not a function of $z$.\footnote{
The derivative is a linear operator, and
$\nabla\sum_z q(z\mid x)B = B \nabla \sum_z q(z\mid x) = B \cdot 0$.
}
Computing this baseline $B$ can be expensive,
potentially requiring multiple evaluations of $p(x\mid z)$.
A common choice of baseline is the sample-average baseline, where
$B = \sum_{z' \in Z} \log p(x\mid z')$
and $Z$ is a set of iid samples.\footnote{
A more efficient alternative is the leave-one-out baseline,
which is efficient if the results of $p(x\mid z)$ are already available
for a set of iid $z$.
}
Additionally, even in scenarios where exact marginalization is tractable,
prior work has included a baseline. This begs the questions:
Is a baseline necessary, and why does optimizing the marginal likelihood
not require a baseline?

We show that the gradient of the marginal likelihood (\ref{eqn:ml-grad}) already contains
a built-in baseline, and use that to derive a simple and computable lower bound
of the marginal likelihood
(\ref{eqn:ml}) whose gradient does not require the manual engineering of a baseline.

\section{The gradient of logsumexp approximates the expoentiated regret}
The key component of the marginal likelihood is the logsumexp operation,
a smooth version of max: $\log \sum_z \exp f(z)$.\footnote{
$\log\sum\exp(f(z))$ is perhaps better known as the log-partition function.
}
Similar to the gradient of the marginal likelihood,
the gradient of logsumexp is given by
$$
\nabla \log \sum_{z'\in Z} \exp f(z')
= \frac{e^{f(z)}}{\sum_{z' \in Z} e^{f(z')}} \nabla f(z)
= e^{f(z) - \log \sum_{z' \in Z} e^{f(z')}} \nabla f(z)
\approx \underbrace{e^{f(z) - \max_{z' \in Z} f(z')}}_{R} \nabla f(z).
$$
The last approximation holds because logsumexp is a smooth approximation of max.
We can therefore think of $\log \sum_{z'\in Z}\exp f(z')\approx \max_{z'\in Z} f(z)$
as a built-in baseline.
$R$ is also the exponentiated regret, the difference between a given $f(z)$
and the best $f(z)$.
Since the regret is non-positive, the exponentiated regret is always between 0 and 1.

\section{Variance analysis}
TBD


\end{document}
